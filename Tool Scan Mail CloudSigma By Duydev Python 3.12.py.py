import os
import sys
import time
import concurrent.futures

try:
    from bs4 import BeautifulSoup # type: ignore
    from pystyle import Colors, Colorate # type: ignore
    import requests # type: ignore
    from tabulate import tabulate # type: ignore
except ImportError:
    os.system("pip install bs4 pystyle beautifulsoup4 requests tabulate")
    from pystyle import Colors, Colorate # type: ignore
    from bs4 import BeautifulSoup # type: ignore
    from tabulate import tabulate # type: ignore
    import requests # type: ignore

den='[1;90m'
luc='[1;32m'
trang='[1;37m'
red='[1;31m'
vang='[1;33m'
lamd='[1;34m'
lam='[1;36m'
duydev=""
duydev=trang+'~'+red+'['+vang+'âŸ¨âŸ©'+red+'] '+trang+'â© '+lam

banners=f"""
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–‘â–ˆâ–ˆâ•—â–‘â–‘â–‘â–ˆâ–ˆâ•—â–ˆâ–ˆâ•—â–‘â–‘â–‘â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—â–‘â–‘â–‘â–ˆâ–ˆâ•—
â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–‘â–‘â–‘â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•—â–‘â–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•‘â–‘â–‘â–‘â–ˆâ–ˆâ•‘
â–ˆâ–ˆâ•‘â–‘â–‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–‘â–‘â–‘â–ˆâ–ˆâ•‘â–‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–‘â–ˆâ–ˆâ•‘â–‘â–‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–‘â–‘â•šâ–ˆâ–ˆâ•—â–‘â–ˆâ–ˆâ•”â•
â–ˆâ–ˆâ•‘â–‘â–‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–‘â–‘â–‘â–ˆâ–ˆâ•‘â–‘â–‘â•šâ–ˆâ–ˆâ•”â•â–‘â–‘â–ˆâ–ˆâ•‘â–‘â–‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â–‘â–‘â–‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–‘
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–‘â–‘â–‘â–ˆâ–ˆâ•‘â–‘â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–‘â–‘â•šâ–ˆâ–ˆâ•”â•â–‘â–‘
â•šâ•â•â•â•â•â•â–‘â–‘â•šâ•â•â•â•â•â•â–‘â–‘â–‘â–‘â•šâ•â•â–‘â–‘â–‘â•šâ•â•â•â•â•â•â–‘â•šâ•â•â•â•â•â•â•â–‘â–‘â–‘â•šâ•â•â–‘â–‘â–‘\n"""

def clear():
    if os.name == 'nt':  
        os.system('cls')
    else:  
        os.system('clear')

def banner():
    print('[0m', end='')
    clear()
    a = Colorate.Horizontal(Colors.blue_to_green, banners)
    for i in range(len(a)):
        sys.stdout.write(a[i])
        sys.stdout.flush()
    print()

def get_uptime(domain):
    try:
        response = requests.post(
            'https://emailfake.com/check_adres_validation3.php',
            data={'usr': 'charleswhatmore', 'dmn': domain}
        )
        data = response.json()
        return int(data.get("uptime", "N/A"))
    except Exception as e:
        print(f"{duydev} ÄÃ£ xáº£y ra lá»—i khi kiá»ƒm tra uptime: {e}")
        return None

def scrape_domains():
    domains = set()
    try:
        response = requests.get("https://emailfake.com/")
        soup = BeautifulSoup(response.text, 'html.parser')
        domain_elements = soup.select("div.e7m.tt-suggestion p")
        
        for domain in domain_elements:
            domain_name = domain['id']
            domains.add(domain_name)
    except Exception as e:
        print(f"{duydev} ÄÃ£ xáº£y ra lá»—i trong quÃ¡ trÃ¬nh thu tháº­p tÃªn miá»n: {e}")
    return list(domains)

def process_domain(domain, max_uptime, output_file, saved_domains, result):
    if domain in saved_domains:
        result['duplicate_domains'] += 1
        return

    uptime = get_uptime(domain)
    if uptime is not None and uptime <= max_uptime:
        saved_domains.add(domain)
        with open(output_file, 'a') as f:
            f.write(f"{domain} (uptime: {uptime} days)\n")
        result['saved_domains'] += 1
    else:
        result['skipped_domains'] += 1

def print_stats(num_threads, total_domains, saved_domains, skipped_domains, duplicate_domains, current_domains  ):
    stats = [
        ["Nháº­p Ctrl + C Ä‘á»ƒ dá»«ng!!"],
        ["Sá»‘ luá»“ng", num_threads],
        ["Tá»•ng tÃªn miá»n", total_domains],
        ["TÃªn miá»n Ä‘Ã£ lÆ°u", saved_domains],
        ["TÃªn miá»n bá» qua", skipped_domains],
        ["TÃªn miá»n trÃ¹ng", duplicate_domains]
    ]
    print(tabulate(stats, headers=["Thá»‘ng kÃª", "GiÃ¡ trá»‹"], tablefmt="grid"))

if __name__ == "__main__":
    clear()
    banner()
    output_file = input(f"\n{duydev} Nháº­p tÃªn file .txt Ä‘á»ƒ lÆ°u káº¿t quáº£ (vÃ­ dá»¥: mail-reg-clsm.txt): ")
    num_domains = int(input(f"{duydev} Nháº­p sá»‘ lÆ°á»£ng tÃªn miá»n cáº§n thu tháº­p vÃ  kiá»ƒm tra uptime: "))
    max_uptime = int(input(f"{duydev} Nháº­p sá»‘ ngÃ y uptime tá»‘i Ä‘a Ä‘á»ƒ lÆ°u: "))
    num_threads = int(input(f"{duydev} Nháº­p sá»‘ luá»“ng Ä‘á»ƒ cháº¡y: "))
    attempt = 1
    saved_domains = set()
    total_domains = 0
    result = {'saved_domains': 0, 'skipped_domains': 0, 'duplicate_domains': 0}

    clear()
    banner()
    print(f"\n{duydev} áº¤n Tá»• Há»£p PhÃ­m Ctrl + C Äá»ƒ Dá»«ng Tool")
    print(f"{duydev} Báº¡n Ä‘ang cháº¡y {num_threads} luá»“ng (phÃ¢n chia giá»¯a thu tháº­p vÃ  kiá»ƒm tra uptime)...")

    try:
        while True:
            print(f"{duydev} Äang thu tháº­p vÃ  kiá»ƒm tra tÃªn miá»n Láº§n {attempt}...")
            num_scrape_threads = num_threads // 2
            num_check_threads = num_threads - num_scrape_threads

            current_domains = 0
            with concurrent.futures.ThreadPoolExecutor(max_workers=num_scrape_threads) as scrape_executor:
                scrape_futures = [scrape_executor.submit(scrape_domains) for _ in range(num_scrape_threads)]
                all_domains = set()

                for future in concurrent.futures.as_completed(scrape_futures):
                    domains = future.result()
                    all_domains.update(domains)

            total_domains += len(all_domains)
            current_domains = len(all_domains)

            if not all_domains:
                print(f"{duydev} KhÃ´ng thu tháº­p Ä‘Æ°á»£c tÃªn miá»n nÃ o.")
                break

            with concurrent.futures.ThreadPoolExecutor(max_workers=num_check_threads) as check_executor:
                check_futures = [check_executor.submit(process_domain, domain, max_uptime, output_file, saved_domains, result) for domain in list(all_domains)[:num_domains]]
                
                for future in concurrent.futures.as_completed(check_futures):
                    future.result()
            clear()
            banner()
            print_stats(num_threads, total_domains, result['saved_domains'], result['skipped_domains'], result['duplicate_domains'], current_domains)

            attempt += 1
            print(f"{duydev} ÄÃ£ háº¿t tÃªn miá»n thu tháº­p trong vÃ²ng nÃ y. Tiáº¿n hÃ nh thu tháº­p tiáº¿p láº§n {attempt}...")
            time.sleep(2)
    except KeyboardInterrupt:
        print(f"{duydev} NgÆ°á»i dÃ¹ng Ä‘Ã£ dá»«ng chÆ°Æ¡ng trÃ¬nh.")
    except Exception as e:
        print(f"{duydev} ÄÃ£ xáº£y ra lá»—i khÃ´ng xÃ¡c Ä‘á»‹nh: {e}")
    finally:
        print(f"{duydev} Táº¡m Biá»‡t!")
